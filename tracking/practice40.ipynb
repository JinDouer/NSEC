{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/torch/cuda/__init__.py:116: UserWarning: \n",
      "    Found GPU2 GeForce GT 740 which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable,Function\n",
    "sys.path.insert(0,'/home/prisimage/tracker/py-MDNetST/modules')\n",
    "from sample_generator import *\n",
    "from data_prov import *\n",
    "from model import *\n",
    "from bbreg import *\n",
    "from options import *\n",
    "from gen_config import *\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import cdist\n",
    "def show_bbox(image,bboxes):\n",
    "    dpi = 80.0\n",
    "    figsize = (image.size[0]/dpi, image.size[1]/dpi)\n",
    "\n",
    "    fig = plt.figure(frameon=False, figsize=figsize, dpi=dpi)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    im = ax.imshow(image, aspect=1)\n",
    "    for i in range(len(bboxes)):\n",
    "        rect = plt.Rectangle(tuple(bboxes[i,:2]),bboxes[i,2],bboxes[i,3], \n",
    "                             linewidth=1, edgecolor=\"#ff0000\", zorder=1, fill=False)\n",
    "        ax.add_patch(rect)\n",
    "def show_result(image,bbox):\n",
    "    dpi = 80.0\n",
    "    figsize = (image.size[0]/dpi, image.size[1]/dpi)\n",
    "\n",
    "    fig = plt.figure(frameon=False, figsize=figsize, dpi=dpi)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    im = ax.imshow(image, aspect=1)\n",
    "    rect = plt.Rectangle(tuple(bbox[:2]),bbox[2],bbox[3], linewidth=1, edgecolor=\"#ff0000\", zorder=1, fill=False)\n",
    "    ax.add_patch(rect)\n",
    "def show_grid(image,samples,num):\n",
    "    image = np.asarray(image)\n",
    "    sample_arr = list()\n",
    "    image = np.asarray(image)\n",
    "    for i in range(num):\n",
    "        sample_img = crop_image(image,samples[i],107,0)\n",
    "        sample_arr.append(sample_img)\n",
    "    d = np.stack(sample_arr,axis=0)\n",
    "    torch_img = torchvision.utils.make_grid(torch.from_numpy(np.transpose(d,(0,3,1,2))))\n",
    "    npimg = torch_img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "def set_optimizer(model, lr_base, lr_mult=opts['lr_mult'], momentum=opts['momentum'], w_decay=opts['w_decay']):\n",
    "    params = model.get_learnable_params()\n",
    "    param_list = []\n",
    "    for k, p in params.iteritems():\n",
    "        lr = lr_base\n",
    "        for l, m in lr_mult.iteritems():\n",
    "            if k.startswith(l):\n",
    "                lr = lr_base * m\n",
    "        param_list.append({'params': [p], 'lr':lr})\n",
    "    optimizer = optim.SGD(param_list, lr = lr, momentum=momentum, weight_decay=w_decay)\n",
    "    return optimizer\n",
    "def show_bbox(image,bboxes):\n",
    "    dpi = 80.0\n",
    "    figsize = (image.size[0]/dpi, image.size[1]/dpi)\n",
    "\n",
    "    fig = plt.figure(frameon=False, figsize=figsize, dpi=dpi)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    im = ax.imshow(image, aspect=1)\n",
    "    for i in range(len(bboxes)):\n",
    "        rect = plt.Rectangle(tuple(bboxes[i,:2]),bboxes[i,2],bboxes[i,3], \n",
    "                             linewidth=1, edgecolor=\"#ff0000\", zorder=1, fill=False)\n",
    "        ax.add_patch(rect)\n",
    "def show_result(image,bbox):\n",
    "    dpi = 80.0\n",
    "    figsize = (image.size[0]/dpi, image.size[1]/dpi)\n",
    "\n",
    "    fig = plt.figure(frameon=False, figsize=figsize, dpi=dpi)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    im = ax.imshow(image, aspect=1)\n",
    "    rect = plt.Rectangle(tuple(bbox[:2]),bbox[2],bbox[3], linewidth=1, edgecolor=\"#ff0000\", zorder=1, fill=False)\n",
    "    ax.add_patch(rect)\n",
    "def forward_samples(model, image, samples, out_layer='conv3'):\n",
    "    model.eval()\n",
    "    extractor = RegionExtractor(image, samples, opts['img_size'], opts['padding'], opts['batch_test'])\n",
    "    for i, regions in enumerate(extractor):\n",
    "        regions = Variable(regions)\n",
    "        if opts['use_gpu']:\n",
    "            regions = regions.cuda()\n",
    "        feat = model(regions, out_layer=out_layer)\n",
    "        if i==0:\n",
    "            feats = feat.data.clone()\n",
    "        else:\n",
    "            feats = torch.cat((feats,feat.data.clone()),0)\n",
    "    return feats\n",
    "def train(model, criterion, optimizer, pos_feats, neg_feats, maxiter, in_layer='fc4'):\n",
    "    model.train()\n",
    "    \n",
    "    batch_pos = opts['batch_pos']\n",
    "    batch_neg = opts['batch_neg']\n",
    "    batch_test = opts['batch_test']\n",
    "    batch_neg_cand = max(opts['batch_neg_cand'], batch_neg)\n",
    "\n",
    "    pos_idx = np.random.permutation(pos_feats.size(0))\n",
    "    neg_idx = np.random.permutation(neg_feats.size(0))\n",
    "    while(len(pos_idx) < batch_pos*maxiter):\n",
    "        pos_idx = np.concatenate([pos_idx, np.random.permutation(pos_feats.size(0))])\n",
    "    while(len(neg_idx) < batch_neg_cand*maxiter):\n",
    "        neg_idx = np.concatenate([neg_idx, np.random.permutation(neg_feats.size(0))])\n",
    "    pos_pointer = 0\n",
    "    neg_pointer = 0\n",
    "\n",
    "    for iter in range(maxiter):\n",
    "\n",
    "        # select pos idx\n",
    "        pos_next = pos_pointer+batch_pos\n",
    "        pos_cur_idx = pos_idx[pos_pointer:pos_next]\n",
    "        pos_cur_idx = pos_feats.new(pos_cur_idx).long()\n",
    "        pos_pointer = pos_next\n",
    "\n",
    "        # select neg idx\n",
    "        neg_next = neg_pointer+batch_neg_cand\n",
    "        neg_cur_idx = neg_idx[neg_pointer:neg_next]\n",
    "        neg_cur_idx = neg_feats.new(neg_cur_idx).long()\n",
    "        neg_pointer = neg_next\n",
    "\n",
    "        # create batch\n",
    "        batch_pos_feats = Variable(pos_feats.index_select(0, pos_cur_idx))\n",
    "        batch_neg_feats = Variable(neg_feats.index_select(0, neg_cur_idx))\n",
    "\n",
    "        # hard negative mining\n",
    "        if batch_neg_cand > batch_neg:\n",
    "            model.eval()\n",
    "            for start in range(0,batch_neg_cand,batch_test):\n",
    "                end = min(start+batch_test,batch_neg_cand)\n",
    "                score = model(batch_neg_feats[start:end], in_layer=in_layer)\n",
    "                if start==0:\n",
    "                    neg_cand_score = score.data[:,1].clone()\n",
    "                else:\n",
    "                    neg_cand_score = torch.cat((neg_cand_score, score.data[:,1].clone()),0)\n",
    "\n",
    "            _, top_idx = neg_cand_score.topk(batch_neg)\n",
    "            batch_neg_feats = batch_neg_feats.index_select(0, Variable(top_idx))\n",
    "            model.train()\n",
    "        \n",
    "        # forward\n",
    "        pos_score = model(batch_pos_feats, in_layer=in_layer)\n",
    "        neg_score = model(batch_neg_feats, in_layer=in_layer)\n",
    "        \n",
    "        # optimize\n",
    "        loss = criterion(pos_score, neg_score)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), opts['grad_clip'])\n",
    "        optimizer.step()\n",
    "\n",
    "        #print \"Iter %d, Loss %.4f\" % (iter, loss.data[0])\n",
    "#import cv2\n",
    "def cvshow(img):\n",
    "    cv2.imshow(\"Image\",img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "        \n",
    "def stackList(featList):\n",
    "    nframes = len(featList)\n",
    "    for start in range(nframes):\n",
    "        if start == 0:\n",
    "            pos_data = featList[start].data.clone()\n",
    "        else:\n",
    "            pos_data = torch.cat((pos_data,featList[start].data.clone()),0)\n",
    "    return pos_data\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(456)\n",
    "torch.cuda.manual_seed(789)\n",
    "seq_home = '../dataset/OTB'\n",
    "save_home = '../result_fig'\n",
    "result_home = '../result'\n",
    "        \n",
    "seq_name = 'Bolt2'\n",
    "img_dir = os.path.join(seq_home, seq_name, 'img')\n",
    "gt_path = os.path.join(seq_home, seq_name, 'groundtruth_rect.txt')\n",
    "\n",
    "img_list = os.listdir(img_dir)\n",
    "img_list.sort()\n",
    "img_list = [os.path.join(img_dir,x) for x in img_list]\n",
    "\n",
    "gt = np.loadtxt(gt_path,delimiter=',')\n",
    "init_bbox = gt[0]\n",
    "        \n",
    "savefig_dir = os.path.join(save_home,seq_name)\n",
    "result_dir = os.path.join(result_home,seq_name)\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "result_path = os.path.join(result_dir,'result.json')\n",
    "# get imglist,gt\n",
    "target_bbox = np.array(init_bbox)\n",
    "result = np.zeros((len(img_list),4))\n",
    "result_bb = np.zeros((len(img_list),4))\n",
    "result[0] = target_bbox\n",
    "result_bb[0] = target_bbox\n",
    "#init the first target box and result array\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "model = MDNet(opts['model_path'])\n",
    "if opts['use_gpu']:\n",
    "    model = model.cuda()\n",
    "model.set_learnable_params(opts['ft_layers'])\n",
    "#init model and set learnable layers\n",
    "criterion = BinaryLoss()\n",
    "init_optimizer = set_optimizer(model, opts['lr_init'])\n",
    "update_optimizer = set_optimizer(model, opts['lr_update'])\n",
    "image = Image.open(img_list[0]).convert('RGB')\n",
    "bbreg_examples = gen_samples(SampleGenerator('uniform', image.size, 0.3, 1.5, 1.1),target_bbox, opts['n_bbreg'], opts['overlap_bbreg'], opts['scale_bbreg'])\n",
    "bbreg_feats = forward_samples(model, image, bbreg_examples)\n",
    "bbreg = BBRegressor(image.size)\n",
    "bbreg.train(bbreg_feats, bbreg_examples, target_bbox)\n",
    "#train bbreg\n",
    "pos_examples = gen_samples(SampleGenerator('gaussian', image.size, 1.5, 1.2),target_bbox, opts['n_pos_init'], opts['overlap_pos_init'])\n",
    "neg_examples = np.concatenate([\n",
    "                    gen_samples(SampleGenerator('uniform', image.size, 1, 2, 1.1), \n",
    "                                target_bbox, opts['n_neg_init']//2, opts['overlap_neg_init']),\n",
    "                    gen_samples(SampleGenerator('whole', image.size, 0, 1.2, 1.1),\n",
    "                                target_bbox, opts['n_neg_init']//2, opts['overlap_neg_init'])])\n",
    "neg_examples = np.random.permutation(neg_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = RegionExtractor(image, pos_examples, opts['img_size'], opts['padding'], opts['batch_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.4254,  ...,  0.2744,  0.0000,  0.4057],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.2007,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ..., 14.5961,  4.5773,  8.6209],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  6.3186,  ...,  0.0000,  0.0000, 16.3708],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ..., 22.4544,  9.7250,  5.0653],\n",
       "        [ 0.0000,  0.0000,  6.8167,  ...,  8.4822,  3.7424, 18.7314]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbreg_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a6b381a041e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/prisimage/tracker/py-MDNetST/tracking/data_prov.pyc\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpointer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mnext_pointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpointer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iter(extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0121589b0156>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "aa = next(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    out_layer = 'conv3'\n",
    "    for i, regions in enumerate(extractor):\n",
    "        regions = Variable(regions)\n",
    "        if opts['use_gpu']:\n",
    "            regions = regions.cuda()\n",
    "        feat = model(regions, out_layer=out_layer)\n",
    "        if i==0:\n",
    "            feats = feat.data.clone()\n",
    "        else:\n",
    "            feats = torch.cat((feats,feat.data.clone()),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  39.,   39.,   39.,  ...,   94.,   94.,   94.],\n",
       "          [  41.,   41.,   41.,  ...,   86.,   82.,   82.],\n",
       "          [  43.,   43.,   43.,  ...,   70.,   65.,   64.],\n",
       "          ...,\n",
       "          [  17.,   17.,   17.,  ...,   50.,   50.,   50.],\n",
       "          [  23.,   23.,   23.,  ...,   61.,   61.,   61.],\n",
       "          [  30.,   30.,   30.,  ...,   68.,   68.,   68.]],\n",
       "\n",
       "         [[ -15.,  -15.,  -15.,  ...,   37.,   37.,   37.],\n",
       "          [ -13.,  -13.,  -13.,  ...,   29.,   25.,   25.],\n",
       "          [ -11.,  -11.,  -11.,  ...,   13.,    8.,    7.],\n",
       "          ...,\n",
       "          [ -33.,  -33.,  -33.,  ...,   -2.,   -2.,   -2.],\n",
       "          [ -28.,  -28.,  -28.,  ...,    8.,    8.,    8.],\n",
       "          [ -22.,  -22.,  -22.,  ...,   13.,   13.,   13.]],\n",
       "\n",
       "         [[ -39.,  -39.,  -39.,  ...,    8.,    8.,    8.],\n",
       "          [ -37.,  -37.,  -37.,  ...,    0.,   -4.,   -4.],\n",
       "          [ -35.,  -35.,  -35.,  ...,  -16.,  -21.,  -22.],\n",
       "          ...,\n",
       "          [ -54.,  -54.,  -54.,  ...,  -24.,  -24.,  -24.],\n",
       "          [ -49.,  -49.,  -49.,  ...,  -13.,  -13.,  -13.],\n",
       "          [ -43.,  -43.,  -43.,  ...,   -8.,   -8.,   -8.]]],\n",
       "\n",
       "\n",
       "        [[[  39.,   38.,   37.,  ...,   67.,   57.,   53.],\n",
       "          [  34.,   34.,   35.,  ...,   51.,   48.,   47.],\n",
       "          [  36.,   37.,   38.,  ...,   48.,   48.,   48.],\n",
       "          ...,\n",
       "          [  51.,   46.,   34.,  ...,   25.,   26.,   27.],\n",
       "          [ 100.,   96.,   87.,  ...,   26.,   29.,   30.],\n",
       "          [  81.,   85.,   93.,  ...,   18.,   19.,   19.]],\n",
       "\n",
       "         [[ -15.,  -16.,  -17.,  ...,   10.,    0.,   -4.],\n",
       "          [ -20.,  -20.,  -19.,  ...,   -6.,   -9.,  -10.],\n",
       "          [ -16.,  -15.,  -15.,  ...,   -9.,  -10.,  -10.],\n",
       "          ...,\n",
       "          [   0.,   -5.,  -17.,  ...,  -27.,  -26.,  -25.],\n",
       "          [  49.,   45.,   36.,  ...,  -26.,  -23.,  -22.],\n",
       "          [  30.,   34.,   42.,  ...,  -34.,  -33.,  -33.]],\n",
       "\n",
       "         [[ -39.,  -40.,  -41.,  ...,  -19.,  -29.,  -33.],\n",
       "          [ -44.,  -44.,  -43.,  ...,  -35.,  -38.,  -39.],\n",
       "          [ -47.,  -46.,  -45.,  ...,  -34.,  -35.,  -35.],\n",
       "          ...,\n",
       "          [ -21.,  -26.,  -38.,  ...,  -48.,  -47.,  -46.],\n",
       "          [  28.,   24.,   15.,  ...,  -47.,  -44.,  -43.],\n",
       "          [   9.,   13.,   21.,  ...,  -55.,  -54.,  -54.]]],\n",
       "\n",
       "\n",
       "        [[[  41.,   41.,   42.,  ...,   46.,   45.,   45.],\n",
       "          [  42.,   42.,   43.,  ...,   48.,   48.,   48.],\n",
       "          [  42.,   42.,   43.,  ...,   48.,   49.,   49.],\n",
       "          ...,\n",
       "          [ -29.,  -26.,  -20.,  ...,   64.,   74.,   77.],\n",
       "          [ -20.,  -18.,  -12.,  ...,   43.,   41.,   41.],\n",
       "          [  14.,   13.,   12.,  ...,   23.,   23.,   23.]],\n",
       "\n",
       "         [[ -13.,  -13.,  -12.,  ...,  -11.,  -12.,  -12.],\n",
       "          [ -13.,  -13.,  -12.,  ...,   -9.,  -10.,  -10.],\n",
       "          [ -14.,  -14.,  -14.,  ...,   -8.,   -9.,   -9.],\n",
       "          ...,\n",
       "          [ -80.,  -77.,  -71.,  ...,   12.,   22.,   25.],\n",
       "          [ -71.,  -69.,  -63.,  ...,   -9.,  -11.,  -11.],\n",
       "          [ -37.,  -38.,  -39.,  ...,  -29.,  -29.,  -29.]],\n",
       "\n",
       "         [[ -37.,  -37.,  -36.,  ...,  -40.,  -41.,  -41.],\n",
       "          [ -39.,  -39.,  -38.,  ...,  -33.,  -34.,  -34.],\n",
       "          [ -41.,  -41.,  -40.,  ...,  -31.,  -31.,  -31.],\n",
       "          ...,\n",
       "          [ -99.,  -96.,  -90.,  ...,   -9.,    1.,    4.],\n",
       "          [ -90.,  -88.,  -83.,  ...,  -30.,  -32.,  -32.],\n",
       "          [ -58.,  -59.,  -60.,  ...,  -50.,  -50.,  -50.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[  15.,   18.,   29.,  ...,   41.,   41.,   41.],\n",
       "          [  12.,   17.,   35.,  ...,   37.,   38.,   38.],\n",
       "          [  19.,   24.,   46.,  ...,   35.,   36.,   36.],\n",
       "          ...,\n",
       "          [  16.,   15.,   15.,  ...,   27.,   28.,   29.],\n",
       "          [  25.,   25.,   29.,  ...,   25.,   27.,   28.],\n",
       "          [  34.,   35.,   41.,  ...,   18.,   19.,   19.]],\n",
       "\n",
       "         [[ -24.,  -21.,   -9.,  ...,  -14.,  -15.,  -15.],\n",
       "          [ -26.,  -21.,   -2.,  ...,  -17.,  -18.,  -18.],\n",
       "          [ -18.,  -12.,   11.,  ...,  -19.,  -20.,  -20.],\n",
       "          ...,\n",
       "          [ -35.,  -36.,  -36.,  ...,  -25.,  -24.,  -23.],\n",
       "          [ -26.,  -26.,  -22.,  ...,  -27.,  -25.,  -24.],\n",
       "          [ -17.,  -16.,  -10.,  ...,  -34.,  -33.,  -33.]],\n",
       "\n",
       "         [[ -39.,  -36.,  -23.,  ...,  -37.,  -38.,  -38.],\n",
       "          [ -40.,  -35.,  -15.,  ...,  -41.,  -41.,  -41.],\n",
       "          [ -32.,  -26.,   -2.,  ...,  -43.,  -43.,  -43.],\n",
       "          ...,\n",
       "          [ -56.,  -57.,  -57.,  ...,  -46.,  -45.,  -44.],\n",
       "          [ -47.,  -47.,  -43.,  ...,  -48.,  -46.,  -45.],\n",
       "          [ -38.,  -37.,  -31.,  ...,  -55.,  -54.,  -54.]]],\n",
       "\n",
       "\n",
       "        [[[  41.,   41.,   41.,  ...,   83.,   81.,   81.],\n",
       "          [  42.,   42.,   43.,  ...,   65.,   60.,   60.],\n",
       "          [  43.,   43.,   43.,  ...,   51.,   47.,   46.],\n",
       "          ...,\n",
       "          [  53.,   53.,   52.,  ...,   64.,   63.,   63.],\n",
       "          [  58.,   58.,   58.,  ...,   71.,   69.,   69.],\n",
       "          [  62.,   62.,   62.,  ...,   78.,   75.,   74.]],\n",
       "\n",
       "         [[ -13.,  -13.,  -13.,  ...,   21.,   19.,   19.],\n",
       "          [ -13.,  -13.,  -13.,  ...,    5.,    1.,    0.],\n",
       "          [ -13.,  -13.,  -13.,  ...,   -7.,  -11.,  -12.],\n",
       "          ...,\n",
       "          [  -1.,   -1.,   -2.,  ...,   18.,   17.,   17.],\n",
       "          [   3.,    3.,    3.,  ...,   26.,   24.,   24.],\n",
       "          [   7.,    7.,    7.,  ...,   34.,   31.,   30.]],\n",
       "\n",
       "         [[ -37.,  -37.,  -37.,  ...,   -4.,   -6.,   -6.],\n",
       "          [ -39.,  -39.,  -39.,  ...,  -18.,  -22.,  -23.],\n",
       "          [ -40.,  -40.,  -40.,  ...,  -29.,  -33.,  -34.],\n",
       "          ...,\n",
       "          [ -22.,  -22.,  -23.,  ...,   -6.,   -7.,   -7.],\n",
       "          [ -17.,  -17.,  -17.,  ...,    2.,    0.,   -1.],\n",
       "          [ -13.,  -13.,  -13.,  ...,    9.,    6.,    5.]]],\n",
       "\n",
       "\n",
       "        [[[  30.,   30.,   29.,  ...,   42.,   42.,   42.],\n",
       "          [  19.,   19.,   18.,  ...,   41.,   41.,   41.],\n",
       "          [  12.,   12.,   10.,  ...,   38.,   39.,   39.],\n",
       "          ...,\n",
       "          [  73.,   71.,   64.,  ...,   19.,   20.,   20.],\n",
       "          [  82.,   82.,   84.,  ...,   21.,   22.,   22.],\n",
       "          [  76.,   79.,   89.,  ...,   24.,   24.,   24.]],\n",
       "\n",
       "         [[ -18.,  -18.,  -18.,  ...,  -14.,  -14.,  -14.],\n",
       "          [ -28.,  -28.,  -28.,  ...,  -14.,  -15.,  -15.],\n",
       "          [ -34.,  -35.,  -35.,  ...,  -16.,  -17.,  -17.],\n",
       "          ...,\n",
       "          [  23.,   20.,   13.,  ...,  -33.,  -32.,  -32.],\n",
       "          [  32.,   32.,   34.,  ...,  -31.,  -30.,  -30.],\n",
       "          [  26.,   29.,   39.,  ...,  -28.,  -28.,  -28.]],\n",
       "\n",
       "         [[ -38.,  -38.,  -37.,  ...,  -37.,  -37.,  -37.],\n",
       "          [ -47.,  -47.,  -46.,  ...,  -37.,  -38.,  -38.],\n",
       "          [ -51.,  -52.,  -52.,  ...,  -40.,  -40.,  -40.],\n",
       "          ...,\n",
       "          [   1.,   -2.,   -9.,  ...,  -54.,  -53.,  -53.],\n",
       "          [   9.,    9.,   11.,  ...,  -52.,  -51.,  -51.],\n",
       "          [   3.,    6.,   16.,  ...,  -49.,  -49.,  -49.]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(127., device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-128., device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
