{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##similarity learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable,Function\n",
    "sys.path.insert(0,'/home/prisimage/tracker/py-MDNetST/modules')\n",
    "from sample_generator import *\n",
    "from data_prov import *\n",
    "from model import *\n",
    "from bbreg import *\n",
    "from options import *\n",
    "from gen_config import *\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import cdist\n",
    "def show_bbox(image,bboxes):\n",
    "    dpi = 80.0\n",
    "    figsize = (image.size[0]/dpi, image.size[1]/dpi)\n",
    "\n",
    "    fig = plt.figure(frameon=False, figsize=figsize, dpi=dpi)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    im = ax.imshow(image, aspect=1)\n",
    "    for i in range(len(bboxes)):\n",
    "        rect = plt.Rectangle(tuple(bboxes[i,:2]),bboxes[i,2],bboxes[i,3], \n",
    "                             linewidth=1, edgecolor=\"#ff0000\", zorder=1, fill=False)\n",
    "        ax.add_patch(rect)\n",
    "def show_result(image,bbox):\n",
    "    dpi = 80.0\n",
    "    figsize = (image.size[0]/dpi, image.size[1]/dpi)\n",
    "\n",
    "    fig = plt.figure(frameon=False, figsize=figsize, dpi=dpi)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    im = ax.imshow(image, aspect=1)\n",
    "    rect = plt.Rectangle(tuple(bbox[:2]),bbox[2],bbox[3], linewidth=1, edgecolor=\"#ff0000\", zorder=1, fill=False)\n",
    "    ax.add_patch(rect)\n",
    "def show_grid(image,samples,num):\n",
    "    image = np.asarray(image)\n",
    "    sample_arr = list()\n",
    "    image = np.asarray(image)\n",
    "    for i in range(num):\n",
    "        sample_img = crop_image(image,samples[i],107,0)\n",
    "        sample_arr.append(sample_img)\n",
    "    d = np.stack(sample_arr,axis=0)\n",
    "    torch_img = torchvision.utils.make_grid(torch.from_numpy(np.transpose(d,(0,3,1,2))))\n",
    "    npimg = torch_img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "def set_optimizer(model, lr_base, lr_mult=opts['lr_mult'], momentum=opts['momentum'], w_decay=opts['w_decay']):\n",
    "    params = model.get_learnable_params()\n",
    "    param_list = []\n",
    "    for k, p in params.iteritems():\n",
    "        lr = lr_base\n",
    "        for l, m in lr_mult.iteritems():\n",
    "            if k.startswith(l):\n",
    "                lr = lr_base * m\n",
    "        param_list.append({'params': [p], 'lr':lr})\n",
    "    optimizer = optim.SGD(param_list, lr = lr, momentum=momentum, weight_decay=w_decay)\n",
    "    return optimizer\n",
    "def show_bbox(image,bboxes):\n",
    "    dpi = 80.0\n",
    "    figsize = (image.size[0]/dpi, image.size[1]/dpi)\n",
    "\n",
    "    fig = plt.figure(frameon=False, figsize=figsize, dpi=dpi)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    im = ax.imshow(image, aspect=1)\n",
    "    for i in range(len(bboxes)):\n",
    "        rect = plt.Rectangle(tuple(bboxes[i,:2]),bboxes[i,2],bboxes[i,3], \n",
    "                             linewidth=1, edgecolor=\"#ff0000\", zorder=1, fill=False)\n",
    "        ax.add_patch(rect)\n",
    "def show_result(image,bbox):\n",
    "    dpi = 80.0\n",
    "    figsize = (image.size[0]/dpi, image.size[1]/dpi)\n",
    "\n",
    "    fig = plt.figure(frameon=False, figsize=figsize, dpi=dpi)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    im = ax.imshow(image, aspect=1)\n",
    "    rect = plt.Rectangle(tuple(bbox[:2]),bbox[2],bbox[3], linewidth=1, edgecolor=\"#ff0000\", zorder=1, fill=False)\n",
    "    ax.add_patch(rect)\n",
    "def forward_samples(model, image, samples, out_layer='conv3'):\n",
    "    model.eval()\n",
    "    extractor = RegionExtractor(image, samples, opts['img_size'], opts['padding'], opts['batch_test'])\n",
    "    for i, regions in enumerate(extractor):\n",
    "        regions = Variable(regions)\n",
    "        if opts['use_gpu']:\n",
    "            regions = regions.cuda()\n",
    "        feat = model(regions, out_layer=out_layer)\n",
    "        if i==0:\n",
    "            feats = feat.data.clone()\n",
    "        else:\n",
    "            feats = torch.cat((feats,feat.data.clone()),0)\n",
    "    return feats\n",
    "def train(model, criterion, optimizer, pos_feats, neg_feats, maxiter, in_layer='fc4'):\n",
    "    model.train()\n",
    "    \n",
    "    batch_pos = opts['batch_pos']\n",
    "    batch_neg = opts['batch_neg']\n",
    "    batch_test = opts['batch_test']\n",
    "    batch_neg_cand = max(opts['batch_neg_cand'], batch_neg)\n",
    "\n",
    "    pos_idx = np.random.permutation(pos_feats.size(0))\n",
    "    neg_idx = np.random.permutation(neg_feats.size(0))\n",
    "    while(len(pos_idx) < batch_pos*maxiter):\n",
    "        pos_idx = np.concatenate([pos_idx, np.random.permutation(pos_feats.size(0))])\n",
    "    while(len(neg_idx) < batch_neg_cand*maxiter):\n",
    "        neg_idx = np.concatenate([neg_idx, np.random.permutation(neg_feats.size(0))])\n",
    "    pos_pointer = 0\n",
    "    neg_pointer = 0\n",
    "\n",
    "    for iter in range(maxiter):\n",
    "\n",
    "        # select pos idx\n",
    "        pos_next = pos_pointer+batch_pos\n",
    "        pos_cur_idx = pos_idx[pos_pointer:pos_next]\n",
    "        pos_cur_idx = pos_feats.new(pos_cur_idx).long()\n",
    "        pos_pointer = pos_next\n",
    "\n",
    "        # select neg idx\n",
    "        neg_next = neg_pointer+batch_neg_cand\n",
    "        neg_cur_idx = neg_idx[neg_pointer:neg_next]\n",
    "        neg_cur_idx = neg_feats.new(neg_cur_idx).long()\n",
    "        neg_pointer = neg_next\n",
    "\n",
    "        # create batch\n",
    "        batch_pos_feats = Variable(pos_feats.index_select(0, pos_cur_idx))\n",
    "        batch_neg_feats = Variable(neg_feats.index_select(0, neg_cur_idx))\n",
    "\n",
    "        # hard negative mining\n",
    "        if batch_neg_cand > batch_neg:\n",
    "            model.eval()\n",
    "            for start in range(0,batch_neg_cand,batch_test):\n",
    "                end = min(start+batch_test,batch_neg_cand)\n",
    "                score = model(batch_neg_feats[start:end], in_layer=in_layer)\n",
    "                if start==0:\n",
    "                    neg_cand_score = score.data[:,1].clone()\n",
    "                else:\n",
    "                    neg_cand_score = torch.cat((neg_cand_score, score.data[:,1].clone()),0)\n",
    "\n",
    "            _, top_idx = neg_cand_score.topk(batch_neg)\n",
    "            batch_neg_feats = batch_neg_feats.index_select(0, Variable(top_idx))\n",
    "            model.train()\n",
    "        \n",
    "        # forward\n",
    "        pos_score = model(batch_pos_feats, in_layer=in_layer)\n",
    "        neg_score = model(batch_neg_feats, in_layer=in_layer)\n",
    "        \n",
    "        # optimize\n",
    "        loss = criterion(pos_score, neg_score)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), opts['grad_clip'])\n",
    "        optimizer.step()\n",
    "\n",
    "        #print \"Iter %d, Loss %.4f\" % (iter, loss.data[0])\n",
    "#import cv2\n",
    "def cvshow(img):\n",
    "    cv2.imshow(\"Image\",img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "        \n",
    "def stackList(featList):\n",
    "    nframes = len(featList)\n",
    "    for start in range(nframes):\n",
    "        if start == 0:\n",
    "            pos_data = featList[start].data.clone()\n",
    "        else:\n",
    "            pos_data = torch.cat((pos_data,featList[start].data.clone()),0)\n",
    "    return pos_data\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(456)\n",
    "torch.cuda.manual_seed(789)\n",
    "seq_home = '../dataset/OTB'\n",
    "save_home = '../result_fig'\n",
    "result_home = '../result'\n",
    "        \n",
    "seq_name = 'Bolt2'\n",
    "img_dir = os.path.join(seq_home, seq_name, 'img')\n",
    "gt_path = os.path.join(seq_home, seq_name, 'groundtruth_rect.txt')\n",
    "\n",
    "img_list = os.listdir(img_dir)\n",
    "img_list.sort()\n",
    "img_list = [os.path.join(img_dir,x) for x in img_list]\n",
    "\n",
    "gt = np.loadtxt(gt_path,delimiter=',')\n",
    "init_bbox = gt[0]\n",
    "        \n",
    "savefig_dir = os.path.join(save_home,seq_name)\n",
    "result_dir = os.path.join(result_home,seq_name)\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "result_path = os.path.join(result_dir,'result.json')\n",
    "# get imglist,gt\n",
    "target_bbox = np.array(init_bbox)\n",
    "result = np.zeros((len(img_list),4))\n",
    "result_bb = np.zeros((len(img_list),4))\n",
    "result[0] = target_bbox\n",
    "result_bb[0] = target_bbox\n",
    "#init the first target box and result array\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "model = MDNet(opts['model_path'])\n",
    "if opts['use_gpu']:\n",
    "    model = model.cuda()\n",
    "model.set_learnable_params(opts['ft_layers'])\n",
    "#init model and set learnable layers\n",
    "criterion = BinaryLoss()\n",
    "init_optimizer = set_optimizer(model, opts['lr_init']*200)\n",
    "update_optimizer = set_optimizer(model, opts['lr_update'])\n",
    "image = Image.open(img_list[0]).convert('RGB')\n",
    "bbreg_examples = gen_samples(SampleGenerator('uniform', image.size, 0.3, 1.5, 1.1),target_bbox, opts['n_bbreg'], opts['overlap_bbreg'], opts['scale_bbreg'])\n",
    "bbreg_feats = forward_samples(model, image, bbreg_examples)\n",
    "bbreg = BBRegressor(image.size)\n",
    "bbreg.train(bbreg_feats, bbreg_examples, target_bbox)\n",
    "#train bbreg\n",
    "pos_examples = gen_samples(SampleGenerator('gaussian', image.size, 1.5, 1.2),target_bbox, opts['n_pos_init'], opts['overlap_pos_init'])\n",
    "neg_examples = np.concatenate([\n",
    "                    gen_samples(SampleGenerator('uniform', image.size, 1, 2, 1.1), \n",
    "                                target_bbox, opts['n_neg_init']//2, opts['overlap_neg_init']),\n",
    "                    gen_samples(SampleGenerator('whole', image.size, 0, 1.2, 1.1),\n",
    "                                target_bbox, opts['n_neg_init']//2, opts['overlap_neg_init'])])\n",
    "neg_examples = np.random.permutation(neg_examples)\n",
    "pos_feats = forward_samples(model, image, pos_examples)\n",
    "neg_feats = forward_samples(model, image, neg_examples)\n",
    "feat_dim = pos_feats.size(-1)\n",
    "#get init pos/neg feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    maxiter = 100\n",
    "    model.train()\n",
    "    \n",
    "    batch_pos = opts['batch_pos']\n",
    "    batch_neg = opts['batch_neg']\n",
    "    batch_test = opts['batch_test']\n",
    "    #batch_neg_cand = max(opts['batch_neg_cand'], batch_neg)\n",
    "\n",
    "    pos_idx = np.random.permutation(pos_feats.size(0))\n",
    "    neg_idx = np.random.permutation(neg_feats.size(0))\n",
    "    while(len(pos_idx) < batch_pos*maxiter):\n",
    "        pos_idx = np.concatenate([pos_idx, np.random.permutation(pos_feats.size(0))])\n",
    "    while(len(neg_idx) < batch_neg*maxiter):\n",
    "        neg_idx = np.concatenate([neg_idx, np.random.permutation(neg_feats.size(0))])\n",
    "    pos_pointer = 0\n",
    "    neg_pointer = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # select pos idx\n",
    "        pos_next = pos_pointer+batch_pos\n",
    "        pos_cur_idx = pos_idx[pos_pointer:pos_next]\n",
    "        pos_cur_idx = pos_feats.new(pos_cur_idx).long()\n",
    "        pos_pointer = pos_next\n",
    "\n",
    "        # select neg idx\n",
    "        neg_next = neg_pointer+batch_neg\n",
    "        neg_cur_idx = neg_idx[neg_pointer:neg_next]\n",
    "        neg_cur_idx = neg_feats.new(neg_cur_idx).long()\n",
    "        neg_pointer = neg_next\n",
    "\n",
    "        # create batch\n",
    "        batch_pos_feats = Variable(pos_feats.index_select(0, pos_cur_idx))\n",
    "        batch_neg_feats = Variable(neg_feats.index_select(0, neg_cur_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # forward\n",
    "        pos_fc5 = model(batch_pos_feats, in_layer='fc4',out_layer='fc5')\n",
    "        neg_fc5 = model(batch_neg_feats, in_layer='fc4',out_layer='fc5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairwiseDistance(Function):\n",
    "    def __init__(self):\n",
    "        super(PairwiseDistance, self).__init__()\n",
    "        \n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x2 = torch.unsqueeze(x2,dim=1)\n",
    "        diff = x2 - x1\n",
    "        dist = torch.pow(diff,2).sum(dim=2)\n",
    "        dist = dist/torch.max(dist,dim = 0)[0]\n",
    "        #distance = torch.mean(dist)\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdist = PairwiseDistance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.0000  0.6797  0.6675  ...   0.5894  0.4990  0.5527\n",
       " 0.6957  0.0000  0.8829  ...   0.8146  0.6606  0.7076\n",
       " 0.7104  0.9180  0.0000  ...   0.6853  0.7543  0.8296\n",
       "          ...             â‹±             ...          \n",
       " 0.5140  0.6941  0.5615  ...   0.0000  0.4094  0.5638\n",
       " 0.4743  0.6134  0.6736  ...   0.4462  0.0000  0.6424\n",
       " 0.6211  0.7769  0.8760  ...   0.7265  0.7596  0.0000\n",
       "[torch.cuda.FloatTensor of size 32x32 (GPU 0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_p = pdist.forward(pos_fc5,pos_fc5)\n",
    "d_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.2714\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_n = pdist.forward(pos_fc5,neg_fc5)\n",
    "d_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.6966\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(d_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 224\n",
       "[torch.cuda.ByteTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(d_p>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.6606\n",
       " 0.8864\n",
       " 0.8101\n",
       " 0.7444\n",
       " 0.0000\n",
       " 0.7907\n",
       " 0.7194\n",
       " 0.7431\n",
       " 0.7847\n",
       " 0.8233\n",
       " 0.5967\n",
       " 0.6235\n",
       " 0.7911\n",
       " 0.6705\n",
       " 0.9157\n",
       " 0.7604\n",
       " 0.7263\n",
       " 0.6984\n",
       " 0.7477\n",
       " 0.8088\n",
       " 0.6224\n",
       " 0.7086\n",
       " 0.7994\n",
       " 0.7987\n",
       " 0.7812\n",
       " 0.7364\n",
       " 0.8822\n",
       " 0.8562\n",
       " 0.7014\n",
       " 0.6730\n",
       " 0.7461\n",
       " 0.6404\n",
       "[torch.cuda.FloatTensor of size 32 (GPU 0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_p[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
